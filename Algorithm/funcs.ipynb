{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original code**: [Babak Khavari](https://github.com/babakkhavari)<br>\n",
    "**Conceptualization & Methodological review** : [Babak Khavari](https://github.com/babakkhavari)<br>\n",
    "**Updates, Modifications**: [Babak Khavari](https://github.com/babakkhavari)<br>\n",
    "\n",
    "# Functions\n",
    "\n",
    "The following noteboook includes the packages and functions used in the main-file to produce. \n",
    "\n",
    "**Note:** Changing this file might break the clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "from rasterio.fill import fillnodata\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import rasterio\n",
    "import json\n",
    "import pandas as pd\n",
    "from osgeo import gdal, ogr, osr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipRasterByExtent(raster, polygon):\n",
    "    \"\"\"\n",
    "    Clipping a raster to the extent of a polygon layer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : raster\n",
    "        Raster dataset to clip\n",
    "    arg2 : polygon\n",
    "        Polygon layer to clip by \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    A clipped raster layer\n",
    "    \"\"\"\n",
    "    \n",
    "    bbox = polygon.total_bounds\n",
    "    bbox2 = [bbox[0], bbox[3], bbox[2], bbox[1]]\n",
    "    clipped = gdal.Translate('', raster, format = 'MEM', projWin = bbox2, noData = 0)\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclassify raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassifyRasters(raster, threshold):    \n",
    "    \"\"\"\n",
    "    Reclassify the rasters, setting the cells below the threshold of each raster dataset to 0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : raster\n",
    "        Raster dataset to reclassify. This is the clipped rasters from the previous cell\n",
    "    arg2 : threshold \n",
    "        Threshold used in order to remove everything below the threshold to zero.  \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    A reclassified raster layer without values under the threshold  \n",
    "    \"\"\"\n",
    "    \n",
    "    driver = gdal.GetDriverByName(\"MEM\")\n",
    "    band = raster.GetRasterBand(1)\n",
    "    lista = band.ReadAsArray()\n",
    "    \n",
    "    lista[np.where(threshold >= lista)] = 0\n",
    "    lista[np.where((threshold < lista) & (lista < 99999))] = 1\n",
    "\n",
    "    raster2 = driver.Create('', raster.RasterXSize , raster.RasterYSize , 1, gdal.GDT_Float32)\n",
    "    raster2.GetRasterBand(1).WriteArray(lista)\n",
    "\n",
    "    proj = raster.GetProjection()\n",
    "    georef = raster.GetGeoTransform()\n",
    "    raster2.SetProjection(proj)\n",
    "    raster2.SetGeoTransform(georef)\n",
    "    raster2.FlushCache()\n",
    "    \n",
    "    return raster2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRaster(raster, factor):\n",
    "    \"\"\"\n",
    "    Resample rasters by a specified factor \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : raster\n",
    "        Raster dataset to resample.\n",
    "    arg2 : factor \n",
    "        Factor used for the resampling.   \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Resampled raster layer with the each side of the pixels being a specified factor larger than the original pixel \n",
    "    \"\"\"\n",
    "    \n",
    "    gt =raster.GetGeoTransform()\n",
    "    xRes = factor*gt[1]\n",
    "    yRes = factor*gt[1]\n",
    "    kwargs1 = {'noData':'0'}\n",
    "    resamp1 = gdal.Translate('',raster, format ='MEM', **kwargs1)\n",
    "    kwargs2 = {'xRes': xRes, 'yRes': yRes, 'resampleAlg': \"mode\"}    \n",
    "    resampled = gdal.Translate('',resamp1, format ='MEM', noData = 0, **kwargs2)\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterize Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize(vector, vector_path, raster, output):\n",
    "    \"\"\"\n",
    "    Converts vector layer to raster. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : vector\n",
    "        Vector layer to convert to raster\n",
    "    arg2 : vector_path \n",
    "        The path of the vector layer that you is to be converted\n",
    "    arg3 : raster\n",
    "        Raster to use as template for the rasterization\n",
    "    arg4 : output\n",
    "        Path to the output raster\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Rasterized vector layer\n",
    "    \"\"\"\n",
    "    \n",
    "    vector[\"id\"] = np.arange(len(vector))+1\n",
    "    vector.to_file(vector_path)\n",
    "\n",
    "    geo_transform = raster.GetGeoTransform()\n",
    "    x_min = geo_transform[0]\n",
    "    y_max = geo_transform[3]\n",
    "    x_max = x_min + geo_transform[1] * raster.RasterXSize\n",
    "    y_min = y_max + geo_transform[5] * raster.RasterYSize\n",
    "    x_res = raster.RasterXSize\n",
    "    y_res = raster.RasterYSize\n",
    "    mb_v = ogr.Open(vector_path)\n",
    "    mb_l = mb_v.GetLayer()\n",
    "    pixel_width = geo_transform[1]\n",
    "    target_ds = gdal.GetDriverByName('GTiff').Create(output, x_res, y_res, 1, gdal.GDT_Byte)\n",
    "    target_ds.SetGeoTransform((x_min, pixel_width, 0, y_max, 0, -pixel_width))\n",
    "    target_dsSRS = osr.SpatialReference()\n",
    "    target_dsSRS.ImportFromEPSG(4326)\n",
    "    target_ds.SetProjection(target_dsSRS.ExportToWkt())\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    NoData_value = -999999\n",
    "    band.SetNoDataValue(NoData_value)\n",
    "    band.FlushCache()\n",
    "    gdal.RasterizeLayer(target_ds, [1], mb_l, options=[\"ATTRIBUTE=id\"])\n",
    "    target_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastercalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterMultiplication(rstpth1,rstpth2, output, filetype = gdal.GDT_Float32):\n",
    "    \"\"\"\n",
    "    Multiplies raster layers. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : rstpth1\n",
    "        Path of the first raster\n",
    "    arg2 : rstpth2 \n",
    "        Path of the second raster\n",
    "    arg3 : output\n",
    "        Path to the output raster\n",
    "    arg4 : filetype\n",
    "        Raster filetype    \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Rasterproduct of two rasters\n",
    "    \"\"\"\n",
    "    \n",
    "    rst1 = gdal.Open(rstpth1)\n",
    "    band_data1 = rst1.GetRasterBand(1)\n",
    "    a = band_data1.ReadAsArray()\n",
    "\n",
    "    rst2 = gdal.Open(rstpth2)\n",
    "    band_data2 = rst2.GetRasterBand(1)\n",
    "    b = band_data2.ReadAsArray()\n",
    "    \n",
    "    f = b * a\n",
    "        \n",
    "    ref = gdal.Open(rstpth1)\n",
    "    band = ref.GetRasterBand(1)\n",
    "    proj = ref.GetProjection()\n",
    "    geotransform = ref.GetGeoTransform()\n",
    "    xsize = band.XSize\n",
    "    ysize = band.YSize\n",
    "    \n",
    "    driver = gdal.GetDriverByName('GTiff') \n",
    "    out = driver.Create(output, xsize, ysize, 1, filetype)\n",
    "    out.GetRasterBand(1).WriteArray(f) \n",
    "    \n",
    "    out.SetProjection(proj)\n",
    "    out.SetGeoTransform(geotransform)\n",
    "    out.FlushCache()\n",
    "    out = None\n",
    "    x = gdal.Open(output)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPolygon(Raster, opt, output):\n",
    "    \"\"\"\n",
    "    Polygonizes a raster layer. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : Raster\n",
    "        Raster to convert to polygon\n",
    "    arg2 : opt\n",
    "        Options that will add an buffer to the NTL polygon\n",
    "    arg3 : crs\n",
    "        Path to the polygon output\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    Polygonized raster\n",
    "    \"\"\" \n",
    "    \n",
    "    if type(Raster) == str:\n",
    "        Raster = gdal.Open(Raster)\n",
    "    \n",
    "    band = Raster.GetRasterBand(1)\n",
    "    bandArray = band.ReadAsArray()\n",
    "    \n",
    "    outShapefile = output\n",
    "    \n",
    "    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    if os.path.exists(outShapefile+\".shp\"):\n",
    "        driver.DeleteDataSource(outShapefile+\".shp\")\n",
    "    outDatasource = driver.CreateDataSource(outShapefile+ \".shp\")\n",
    "    \n",
    "    outLayer = outDatasource.CreateLayer(outShapefile+ \".shp\", srs=None)\n",
    "    newField = ogr.FieldDefn('PLACEHOLDE', ogr.OFTInteger)\n",
    "    outLayer.CreateField(newField)\n",
    "    gdal.Polygonize(band, band, outLayer, 0, [\"8CONNECTED=8\",\"GROUPBY=PLACEHOLDE\"], callback=None)\n",
    "    outDatasource.Destroy()\n",
    "    sourceRaster = None\n",
    "        \n",
    "    if opt == 1:\n",
    "        out = gpd.read_file(outShapefile+\".shp\")\n",
    "    else:\n",
    "        NTLArea=gpd.read_file(outShapefile+\".shp\")\n",
    "        clean = NTLArea[NTLArea.PLACEHOLDE != 0]\n",
    "        clean_b = clean.buffer(0)\n",
    "        clean_b.crs = {'init' :'epsg:4326'}\n",
    "        out = clean_b\n",
    "        \n",
    "    return out      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split multipart to single part (for vector polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi2single(gpdf):\n",
    "    gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']\n",
    "    gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']\n",
    "\n",
    "    for i, row in gpdf_multipoly.iterrows():\n",
    "        Series_geometries = pd.Series(row.geometry)\n",
    "        df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T]*len(Series_geometries), ignore_index=True)\n",
    "        df['geometry']  = Series_geometries\n",
    "        gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])\n",
    "\n",
    "    gpdf_singlepoly.reset_index(inplace=True, drop=True)\n",
    "    return gpdf_singlepoly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip raster by mask and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipRasterByMask(raster_path, mask_path, crs, output):\n",
    "    \"\"\"\n",
    "    Clipping raster by a polygon mask. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : raster_path\n",
    "        Raster to clip\n",
    "    arg2 : mask_path\n",
    "        Polygon vector to clip by\n",
    "    arg3 : crs\n",
    "        Coordinate reference system of the clipped raster\n",
    "    arg4 : output\n",
    "        Output raster path for clipped raster\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    Clipped raster dataset\n",
    "    \"\"\" \n",
    "    \n",
    "    with fiona.open(mask_path, \"r\") as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "        out_image[out_image<0] = np.nan\n",
    "        mask = (out_image!=0)\n",
    "        out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform,\n",
    "                     \"crs\": crs})\n",
    "    \n",
    "    out_meta.update(compress = 'lzw')\n",
    "    \n",
    "    with rasterio.open(output, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "    out = rasterio.open(output)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save memory raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRaster(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Saving memory raster. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : input_file\n",
    "        Memory raster to save to disc\n",
    "    arg2 : output_file\n",
    "        The path to the save raster\n",
    "    \"\"\" \n",
    "    \n",
    "    kwargs = {'creationOptions': ['COMPRESS=LZW']}\n",
    "    gdal.Warp(output_file, input_file, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding attributes to the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAttributes(clusters, crs, study_area):\n",
    "    \"\"\"\n",
    "    Adds country name and area to the clusters \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : clusters\n",
    "        Population clusters\n",
    "    arg2 : crs\n",
    "        User selected coordinate reference system to reporject the clusters to \n",
    "    arg3 : country\n",
    "        Study area \n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    Population clusters with a study area column and an area column given in square kilometers\n",
    "    \"\"\"\n",
    "    \n",
    "    clusters['id'] = np.arange(len(clusters))\n",
    "    clusters.crs = {'init' :'epsg:4326'}\n",
    "    clusters_proj = clusters.to_crs({ 'init': crs})\n",
    "    clusters_proj[\"Area\"] = clusters_proj.area/1000000\n",
    "    clusters_proj[\"Country\"] = study_area\n",
    "    clusters = clusters_proj.to_crs({ 'init': 'epsg:4326'})\n",
    "    clusters = clusters.drop(['PLACEHOLDE'], axis=1)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populatingClusters(clusters,raster,column,method):\n",
    "    \"\"\"\n",
    "    Adding raster data to clusters \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : clusters\n",
    "        Population clusters\n",
    "    arg2 : raster\n",
    "        Raster to add the clusters \n",
    "    arg3 : column\n",
    "        Name of column with added raster statitics\n",
    "    arg4 : method    \n",
    "        Method used in order to aggregate the raster data for each raster \n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    Population clusters with raster statistics added\n",
    "    \"\"\"\n",
    "    \n",
    "    clusters = zonal_stats(\n",
    "    clusters,\n",
    "    raster.name,\n",
    "    stats=[method],\n",
    "    prefix=column, geojson_out=True, all_touched=True)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibratePop(clusters, workspace, act_pop):\n",
    "    \"\"\"\n",
    "    Adding raster data to clusters \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : clusters\n",
    "        Population clusters\n",
    "    arg2 : workspace\n",
    "        Output path for the output clusters\n",
    "    arg3 : act_pop\n",
    "        The actual population in the study area given by the user\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    Final population clusters\n",
    "    \"\"\"\n",
    "        \n",
    "    output = workspace + r'\\placeholder.geojson'\n",
    "    with open(output, \"w\") as dst:\n",
    "        collection = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": list(clusters)}\n",
    "        dst.write(json.dumps(collection))\n",
    "  \n",
    "    clusters = gpd.read_file(output)\n",
    "    os.remove(output)\n",
    "    \n",
    "    clusters = clusters.rename(columns={\"Popsum\": \"Population\"})\n",
    "    clusters = clusters.rename(columns={\"NTLmax\": \"NightLight\"})\n",
    "    clusters = clusters.rename(columns={\"ElecPopsum\": \"ElecPop\"})\n",
    "    \n",
    "    clusters[\"Population\"].fillna(0, inplace=True)\n",
    "    clusters[\"NightLight\"].fillna(0, inplace=True)\n",
    "    clusters[\"ElecPop\"].fillna(0, inplace=True)\n",
    "    pop_tot = clusters[\"Population\"].sum()\n",
    "    \n",
    "    ratio= act_pop/pop_tot\n",
    "    clusters[\"Population\"] = clusters[\"Population\"]*ratio\n",
    "    clusters[\"ElecPop\"] = clusters[\"ElecPop\"]*ratio\n",
    "    clusters_filter = clusters[clusters['Population'] > 0]\n",
    "    clusters_filter.loc[clusters_filter[\"NightLight\"] == 0, [\"ElecPop\"]] = 0\n",
    "\n",
    "    clusters_filter.to_file(workspace + r\"\\clusters.shp\")\n",
    "    clusters = gpd.read_file(workspace + r\"\\clusters.shp\")\n",
    "    \n",
    "    dir_name = workspace\n",
    "    test = os.listdir(dir_name)\n",
    "\n",
    "    for item in test:\n",
    "        if item.endswith(\".tif\") or item.startswith(\"NTLArea\") or item.startswith(\"bufferedlines\"):\n",
    "            os.remove(os.path.join(dir_name, item))\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urban/rural split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrateUrban(clusters, urban_current, workspace):\n",
    "    \"\"\"\n",
    "    Calibrate urban population. Classifies clusters to either urban(2), peri-urban(1) or rural(0). \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : clusters\n",
    "        Population clusters with population column\n",
    "    arg2 : urban_current\n",
    "        Urban ration defined by the user\n",
    "    arg3 : workspace\n",
    "        Output folder in which the clusters as saved after the urban classification\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Population clusters with an ubran-rural classifcation column \n",
    "    \"\"\"\n",
    "    \n",
    "    urban_modelled = 2\n",
    "    factor = 1\n",
    "    pop_tot = clusters[\"Population\"].sum()\n",
    "    i = 0\n",
    "    while abs(urban_modelled - urban_current) > 0.01:\n",
    "        clusters[\"IsUrban\"] = 0\n",
    "        clusters.loc[(clusters[\"Population\"] > 5000 * factor) & (\n",
    "            clusters[\"Population\"] / clusters[\"Area\"] > 350 * factor), \"IsUrban\"] = 1\n",
    "        clusters.loc[(clusters[\"Population\"] > 50000 * factor) & (\n",
    "            clusters[\"Population\"] / clusters[\"Area\"] > 1500 * factor), \"IsUrban\"] = 2\n",
    "        pop_urb = clusters.loc[clusters[\"IsUrban\"] > 1, \"Population\"].sum()\n",
    "        \n",
    "        urban_modelled = pop_urb / pop_tot\n",
    "        \n",
    "        if urban_modelled > urban_current:\n",
    "            factor *= 1.1\n",
    "        else:\n",
    "            factor *= 0.9\n",
    "        i=i+1\n",
    "        if i > 500:\n",
    "            break\n",
    "            print(i)\n",
    "    \n",
    "    clusters.to_file(workspace + r\"/clusters.shp\") \n",
    "    \n",
    "    print(\"Modelled urban ratio is \" + str(round(urban_modelled, 3)) + \"% in comparision to the actual ratio of \" + str(urban_current) + \"% after \" + str(i) + \" iterations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
